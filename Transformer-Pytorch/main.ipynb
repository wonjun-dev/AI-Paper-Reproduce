{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data and preprocess pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set tokenizer and build vocabulary\n",
    "from torchtext.datasets import Multi30k\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "\n",
    "en_tokenizer = get_tokenizer('spacy', language='en_core_web_md')\n",
    "de_tokenizer = get_tokenizer('spacy', language='de_core_news_md')\n",
    "\n",
    "def yield_tokens(data_iter, language: str):\n",
    "    for text in data_iter:\n",
    "        if language == 'en':\n",
    "            yield en_tokenizer(text[0])\n",
    "        elif language == 'de':\n",
    "            yield de_tokenizer(text[1])\n",
    "\n",
    "UNK_IDX, PAD_IDX, BOS_IDX, EOS_IDX = 0, 1, 2, 3\n",
    "special_tokens = ['<unk>', '<pad>', '<bos>', '<eos>']\n",
    "en_vocab = build_vocab_from_iterator(yield_tokens(Multi30k(split='train', language_pair=('en', 'de')), 'en'), specials=special_tokens, special_first=True, min_freq=3)\n",
    "de_vocab = build_vocab_from_iterator(yield_tokens(Multi30k(split='train', language_pair=('en', 'de')), 'de'), specials=special_tokens, special_first=True, min_freq=3)\n",
    "en_vocab.set_default_index(UNK_IDX) # oov 일때 반환하는 토큰\n",
    "de_vocab.set_default_index(UNK_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[166, 37, 8, 336, 288, 18, 1225, 4, 759, 4497, 2958, 6]\n",
      "[85, 32, 11, 848, 2209, 16, 0, 5]\n"
     ]
    }
   ],
   "source": [
    "# Set preprocess pipeline\n",
    "en_pipeline = lambda x: en_vocab(en_tokenizer(x))\n",
    "de_pipeline = lambda x: de_vocab(de_tokenizer(x))\n",
    "trasnform_pipeline = {'en': en_pipeline, 'de': de_pipeline}\n",
    "print(en_pipeline('Several men in hard hats are operating a giant pulley system.'))\n",
    "print(de_pipeline('Mehrere Männer mit Schutzhelmen bedienen ein Antriebsradsystem.'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data.backward_compatibility import worker_init_fn\n",
    "\n",
    "\n",
    "def collate_func(batch, src_ln: str = 'de', tgt_ln: str = 'en', batch_first: bool = True):\n",
    "    src_batch, tgt_batch = [], []\n",
    "    for src, tgt in batch:\n",
    "        src_ids = trasnform_pipeline[src_ln](src.rstrip('\\n'))\n",
    "        tgt_ids = trasnform_pipeline[tgt_ln](tgt.rstrip('\\n'))\n",
    "        src_ids = torch.cat((torch.tensor([BOS_IDX]), torch.tensor(src_ids), torch.tensor([EOS_IDX])))\n",
    "        tgt_ids = torch.cat((torch.tensor([BOS_IDX]), torch.tensor(tgt_ids), torch.tensor([EOS_IDX])))\n",
    "        src_batch.append(src_ids)\n",
    "        tgt_batch.append(tgt_ids)\n",
    "\n",
    "    src_batch = pad_sequence(src_batch, padding_value=PAD_IDX, batch_first=batch_first)\n",
    "    tgt_batch = pad_sequence(tgt_batch, padding_value=PAD_IDX, batch_first=batch_first)\n",
    "    \n",
    "    return src_batch, tgt_batch\n",
    "\n",
    "\n",
    "\n",
    "train_iter, valid_iter, test_iter = Multi30k(root='./data', split=('train', 'valid', 'test'), language_pair=('de', 'en'))\n",
    "train_loader = DataLoader(list(train_iter), batch_size=128, collate_fn=collate_func, num_workers=8, shuffle=True)\n",
    "valid_loader = DataLoader(list(valid_iter), batch_size=1, collate_fn=collate_func)\n",
    "test_loader = DataLoader(list(test_iter), batch_size=1, collate_fn=collate_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch.nn as nn\n",
    "from torch import Tensor\n",
    "\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, emb_size: int = 512, dropout: float = 0.1, max_len: int = 5000, device=None) -> None:\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        pos = torch.arange(0, max_len).reshape(max_len, 1)\n",
    "        val = torch.exp(-torch.arange(0, emb_size, 2) / emb_size * math.log(10000))\n",
    "        pos_encoding = torch.zeros((max_len, emb_size))\n",
    "        pos_encoding[:, 0::2] = torch.sin(pos * val)\n",
    "        pos_encoding[:, 1::2] = torch.cos(pos * val)\n",
    "        pos_encoding = pos_encoding.unsqueeze(0).to(device)    # batch first\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.register_buffer('pos_encoding', pos_encoding)\n",
    "    \n",
    "    def forward(self, token_embedding: Tensor) -> Tensor:\n",
    "        return self.dropout(token_embedding + self.pos_encoding[:, :token_embedding.size(1), :])\n",
    "\n",
    "class TokenEmbedding(nn.Module):\n",
    "    def __init__(self, vocab_size: int, emb_size: int = 512, device=None) -> None:\n",
    "        super(TokenEmbedding, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, emb_size, device=device)\n",
    "        self.emb_size = emb_size\n",
    "    \n",
    "    def forward(self, tokens: Tensor) -> Tensor:\n",
    "        return self.embedding(tokens.long()) * math.sqrt(self.emb_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "from torch.nn.init import xavier_uniform_\n",
    "\n",
    "from transformer import Transformer\n",
    "\n",
    "\n",
    "class TransformerWrapper(nn.Module):\n",
    "    def __init__(self, emb_size: int, src_vocab_size: int, tgt_vocab_size: int, device=None, dtype=None):\n",
    "        super(TransformerWrapper, self).__init__()\n",
    "        self.transformer = Transformer(d_model=emb_size, num_encoder_layers=3, num_decoder_layers=3, n_head=8, dim_feedforward=1024, batch_first=True, device=device)\n",
    "        self.generator = nn.Linear(emb_size, tgt_vocab_size, device=device)\n",
    "        self.src_tok_emb = TokenEmbedding(src_vocab_size, emb_size, device=device)\n",
    "        self.tgt_tok_emb = TokenEmbedding(tgt_vocab_size, emb_size, device=device)\n",
    "        self.pos_encoding = PositionalEncoding(emb_size=emb_size, device=device)\n",
    "\n",
    "        self._reset_params()\n",
    "        \n",
    "    \n",
    "    def forward(self, src: Tensor, tgt: Tensor, src_mask: Optional[Tensor] = None, tgt_mask: Optional[Tensor] = None, memory_mask: Optional[Tensor] = None):\n",
    "        src_emb = self.pos_encoding(self.src_tok_emb(src))\n",
    "        tgt_emb = self.pos_encoding(self.tgt_tok_emb(tgt))\n",
    "        output = self.transformer(src_emb, tgt_emb, src_mask=src_mask, tgt_mask=tgt_mask, memory_mask=memory_mask)\n",
    "        return self.generator(output)\n",
    "\n",
    "    def encode(self, src: Tensor, src_mask: Tensor) -> Tensor:\n",
    "        src_emb = self.pos_encoding(self.src_tok_emb(src))\n",
    "        return self.transformer.encoder(src_emb, src_mask)\n",
    "\n",
    "    def decode(self, tgt: Tensor, memory: Tensor, tgt_mask: Tensor) -> Tensor:\n",
    "        tgt_emb = self.pos_encoding(self.tgt_tok_emb(tgt))\n",
    "        return self.transformer.decoder(tgt_emb, memory, tgt_mask)\n",
    "    \n",
    "    def _reset_params(self):\n",
    "        for p in self.parameters():\n",
    "            if p.dim() > 1:\n",
    "                xavier_uniform_(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "\n",
    "def generate_mask(src: Tensor, tgt: Tensor, device=None) -> Tuple[Tensor]:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            src: [N, L]\n",
    "            tgt: [N, L]\n",
    "        \"\"\"\n",
    "        tgt_seq_len = tgt.shape[-1]\n",
    "\n",
    "        \"\"\"\n",
    "        tgt mask\n",
    "        1 0 0 0 0 \n",
    "        1 1 0 0 0\n",
    "        1 1 1 0 0\n",
    "        1 1 1 1 0\n",
    "        1 1 1 1 1\n",
    "        \"\"\"\n",
    "        src_mask = (src != PAD_IDX).unsqueeze(1).unsqueeze(2)\n",
    "        tgt_seq_mask = (torch.triu(torch.ones((tgt_seq_len, tgt_seq_len), device=device)) == 1).transpose(0, 1)\n",
    "        tgt_padding_mask = (tgt != PAD_IDX).unsqueeze(1).unsqueeze(2)\n",
    "\n",
    "        tgt_mask = tgt_seq_mask & tgt_padding_mask\n",
    "\n",
    "\n",
    "        return src_mask, tgt_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 => Train Loss 4.15803920855081 Train PPL 63.9460147938143\n",
      "Epoch 0 => Vaid Loss 3.2433015697101166 Valid PPL 25.61816242635035\n",
      "Epoch 1 => Train Loss 3.0796020839707965 Train PPL 21.749746101467203\n",
      "Epoch 1 => Vaid Loss 2.6508969977880135 Valid PPL 14.166740482640463\n",
      "Epoch 2 => Train Loss 2.438406428576566 Train PPL 11.454772192912776\n",
      "Epoch 2 => Vaid Loss 2.082813606827099 Valid PPL 8.027022055638872\n",
      "Epoch 3 => Train Loss 1.9594577886984736 Train PPL 7.095478773176655\n",
      "Epoch 3 => Vaid Loss 1.8156690316998512 Valid PPL 6.14518612676874\n",
      "Epoch 4 => Train Loss 1.6804517712362013 Train PPL 5.367980522606029\n",
      "Epoch 4 => Vaid Loss 1.6757644856646217 Valid PPL 5.342878141926892\n",
      "Epoch 5 => Train Loss 1.4915613697488928 Train PPL 4.444028877079208\n",
      "Epoch 5 => Vaid Loss 1.6182349434074683 Valid PPL 5.044179192820308\n",
      "Epoch 6 => Train Loss 1.352497707904698 Train PPL 3.867072295321762\n",
      "Epoch 6 => Vaid Loss 1.600491096113149 Valid PPL 4.955465436739591\n",
      "Epoch 7 => Train Loss 1.2380533780295417 Train PPL 3.448893234666634\n",
      "Epoch 7 => Vaid Loss 1.561881180485266 Valid PPL 4.76778187243316\n",
      "Epoch 8 => Train Loss 1.1470076790990282 Train PPL 3.1487567081493153\n",
      "Epoch 8 => Vaid Loss 1.5799541001040966 Valid PPL 4.8547329743852154\n",
      "Epoch 9 => Train Loss 1.06733350659257 Train PPL 2.9076160150008903\n",
      "Epoch 9 => Vaid Loss 1.6009780672439458 Valid PPL 4.957879193014055\n"
     ]
    }
   ],
   "source": [
    "from torch.optim import Adam\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "else:\n",
    "    device = 'cpu'\n",
    "\n",
    "model = TransformerWrapper(emb_size=512, src_vocab_size=len(de_vocab), tgt_vocab_size=len(en_vocab), device=device)\n",
    "loss_fn = nn.CrossEntropyLoss(ignore_index=PAD_IDX)\n",
    "optimizer = Adam(model.parameters(), lr=0.0005)\n",
    "\n",
    "EPOCH = 10\n",
    "GCLIP = 1\n",
    "for e in range(EPOCH):\n",
    "    epoch_loss = 0\n",
    "    model.train()\n",
    "    for src, tgt in train_loader:\n",
    "        src, tgt = src.to(device), tgt.to(device)\n",
    "\n",
    "        tgt_in = tgt[:, :-1]\n",
    "        tgt_out = tgt[:, 1:]\n",
    "        \n",
    "        src_mask, tgt_mask = generate_mask(src, tgt_in, device)\n",
    "\n",
    "        logits = model(src, tgt_in, src_mask=src_mask, tgt_mask=tgt_mask, memory_mask=src_mask)\n",
    "        preds = torch.argmax(logits, dim=-1)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss = loss_fn(logits.reshape(-1, logits.size(-1)), tgt_out.reshape(-1))\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), GCLIP)\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        valid_loss = 0\n",
    "        for src, tgt in valid_loader:\n",
    "            src, tgt = src.to(device), tgt.to(device)\n",
    "            tgt_in = tgt[:, :-1]\n",
    "            tgt_out = tgt[:, 1:]\n",
    "            \n",
    "            src_mask, tgt_mask = generate_mask(src, tgt_in, device)\n",
    "            logits = model(src, tgt_in, src_mask=src_mask, tgt_mask=tgt_mask, memory_mask=src_mask)\n",
    "            loss = loss_fn(logits.reshape(-1, logits.size(-1)), tgt_out.reshape(-1))\n",
    "            valid_loss += loss.item()\n",
    "    \n",
    "    print(f\"Epoch {e} => Train Loss {epoch_loss / len(train_loader)} Train PPL {math.exp(epoch_loss / len(train_loader))}\")\n",
    "    print(f\"Epoch {e} => Vaid Loss {valid_loss / len(valid_loader)} Valid PPL {math.exp(valid_loss / len(valid_loader))}\")\n",
    "\n",
    "torch.save(model.state_dict(), 'model.pt')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load trained Transformer and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TransformerWrapper(\n",
       "  (transformer): Transformer(\n",
       "    (encoder): TransformerEncoder(\n",
       "      (layers): ModuleList(\n",
       "        (0): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (wq): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (wk): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (wv): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (linear1): Linear(in_features=512, out_features=1024, bias=True)\n",
       "          (droput): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=1024, out_features=512, bias=True)\n",
       "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (1): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (wq): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (wk): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (wv): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (linear1): Linear(in_features=512, out_features=1024, bias=True)\n",
       "          (droput): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=1024, out_features=512, bias=True)\n",
       "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (2): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (wq): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (wk): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (wv): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (linear1): Linear(in_features=512, out_features=1024, bias=True)\n",
       "          (droput): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=1024, out_features=512, bias=True)\n",
       "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (decoder): TransformerDecoder(\n",
       "      (layers): ModuleList(\n",
       "        (0): TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (wq): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (wk): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (wv): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (multihead_attn): MultiheadAttention(\n",
       "            (wq): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (wk): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (wv): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (linear1): Linear(in_features=512, out_features=1024, bias=True)\n",
       "          (droput): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=1024, out_features=512, bias=True)\n",
       "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          (dropout3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (1): TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (wq): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (wk): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (wv): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (multihead_attn): MultiheadAttention(\n",
       "            (wq): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (wk): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (wv): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (linear1): Linear(in_features=512, out_features=1024, bias=True)\n",
       "          (droput): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=1024, out_features=512, bias=True)\n",
       "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          (dropout3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (2): TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (wq): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (wk): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (wv): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (multihead_attn): MultiheadAttention(\n",
       "            (wq): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (wk): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (wv): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (linear1): Linear(in_features=512, out_features=1024, bias=True)\n",
       "          (droput): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=1024, out_features=512, bias=True)\n",
       "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          (dropout3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (generator): Linear(in_features=512, out_features=4728, bias=True)\n",
       "  (src_tok_emb): TokenEmbedding(\n",
       "    (embedding): Embedding(5498, 512)\n",
       "  )\n",
       "  (tgt_tok_emb): TokenEmbedding(\n",
       "    (embedding): Embedding(4728, 512)\n",
       "  )\n",
       "  (pos_encoding): PositionalEncoding(\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "else:\n",
    "    device = 'cpu'\n",
    "\n",
    "\n",
    "model = TransformerWrapper(emb_size=512, src_vocab_size=len(de_vocab), tgt_vocab_size=len(en_vocab), device=device)\n",
    "model.load_state_dict(torch.load('model.pt'))\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Two men are playing soccer .\n",
      "The two men are playing soccer on the grass .\n",
      "Two men are playing soccer on a busy day .\n"
     ]
    }
   ],
   "source": [
    "def translate(model, src: str, src_ln: str = 'de', max_len: int = 50, device=None):\n",
    "    model.eval()\n",
    "    if src_ln == 'de':\n",
    "        tgt_vocab = en_vocab.get_itos()\n",
    "    else:\n",
    "        tgt_vocab = de_vocab.get_itos()\n",
    "    \n",
    "    src_ids = trasnform_pipeline[src_ln](src.rstrip('\\n'))\n",
    "    src_ids = torch.cat((torch.tensor([BOS_IDX]), torch.tensor(src_ids), torch.tensor([EOS_IDX])))\n",
    "    src_ids = src_ids.unsqueeze(0).to(device)\n",
    "\n",
    "    src_mask = (src_ids != PAD_IDX).unsqueeze(1).unsqueeze(2).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        memory = model.encode(src_ids, src_mask)\n",
    "\n",
    "    pred_ids = [BOS_IDX]\n",
    "    for i in range(max_len):\n",
    "        pred_tensor = torch.LongTensor(pred_ids).unsqueeze(0).to(device)\n",
    "        tgt_seq_mask = (torch.triu(torch.ones((pred_tensor.shape[-1], pred_tensor.shape[-1]), device=device)) == 1).transpose(0, 1)\n",
    "        tgt_padding_mask = (pred_tensor != PAD_IDX).unsqueeze(1).unsqueeze(2)\n",
    "        tgt_mask = tgt_seq_mask & tgt_padding_mask\n",
    "\n",
    "        with torch.no_grad():\n",
    "            preds = model.decode(pred_tensor, memory, tgt_mask)\n",
    "            preds = model.generator(preds)\n",
    "        \n",
    "        pred_id = preds.argmax(-1)[:, -1].item()\n",
    "        pred_ids.append(pred_id)\n",
    "\n",
    "        if pred_id == EOS_IDX:\n",
    "            break\n",
    "\n",
    "    pred = []\n",
    "    for id in pred_ids[1:-1]:\n",
    "        pred.append(tgt_vocab[id])\n",
    "        \n",
    "    return ' '.join(pred)\n",
    "\n",
    "print(translate(model, 'Zwei Männer spielen Fußball', device=device))\n",
    "print(translate(model, 'Auf dem Rasen spielen zwei Männer Fußball.', device=device))\n",
    "print(translate(model, 'Zwei Männer spielen an einem regnerischen Tag auf dem Rasen Fußball.', device=device))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.9 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7d54d44b476ee03c59f2b2873b2d13a0a58dbc0ce917a1197d2792a3bd70a14c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
